### GENETAL

Vulkan - язык приказов, который CPU использует, чтобы управлять GPU.
Vulkan — это очень строгий и детальный протокол, который описывает, как CPU должен подготовить данные, 
упаковать инструкции и отправить их на выполнение в GPU

### Rendering Pipeline

Это "сборочный конвейер" внутри GPU. Когда вы даете команду нарисовать треугольник, его данные (координаты вершин) проходят через несколько обязательных этапов:
    - Vertex input (Входные данные вершин)
    - Vertex Shader (Вершинный буфер)
    - Rasterization (Растеризация)
    - Fragment Shader (Фрагментный (пиксельный) шейдер)
    - Blending (Смешивание)

1. Vertex input
   GPU нужно получить сырые данные о моей модели из памяти. 
   В initialize я создаю plabe_mesh.vertex_buffer и cube_mesh.vertex_buffer. Это буферы в VRAM (память в GPU),
   куда я копирую данные из векторов vertices. Структура Vertex описывает, что лежит в этом буфере для каждой
   вершины.
2. Vertex Shader
   Маленькая программа, которая выполняется GPU для каждой вершины индивидуально. Задача - взять позицию
   вершины в локальных координатах модели и вычислить ее финальную позицию на экране.
   У меня это происходит в shader.verts
3. Rasterization
   GPU берет 3 обработанные вершины, которые образуют треугольник, и определяет, какие пиксели на экране попадают внутрь. На этом этапе он также интерполирует (плавно изменяет) данные, которые мы получили от вершинного шейдера (например, нормаль f_normal) для каждого пикселя. а этом этапе он также интерполирует (плавно изменяет) данные, которые мы получили от вершинного шейдера (например, нормаль f_normal) для каждого пикселя. Если у одной вершины нормаль смотрит вверх, а у другой вбок, то у пикселя посередине нормаль будет смотреть по диагонали.
   У меня настраивается в initialize через VkPipelineRasterizationStateCreateInfo.
4. Fragment Shader
   Вторая маленькая программа. Выполняется для каждого пикселя, который попал внутрь треугольника на этапе растеризации. Задача - определить, каким цветом будет пиксель. Здесь же происходит "магия" освещения.
   У меня это shader.frag.
5. Blending
   Последний этап. Если пиксель уже чем-то закрашен (например, за треугольником есть другой), GPU решает, что с этим делать. Смешать цвета (для прозрачности) или просто переписать старый цвет новым.
   У меня в коде настраивается в VkPipelineColorBlendStateCreateInfo.


### Передача данных в GPU

1. Vertex Buffers
   Это большие объемы данных, описывающие геометрию. Позиции, нормали, UV-координаты.
   В моем коде plane_mesh.vertex_buffer. Обычно загружаются в VRAM 1 раз и больше не меняются.
2. Uniform Buffers
   Небольшие объемы данных, которые являются общими для целого вызова отрисовки (матрица проекции или позиция камеры). В моем коде: scene_uniforms_buffer (хранит view_projection) - обновляется один раз за кадр; model_uniforms_buffer (хранит model, albedo_color) - Dynamic UBO. Выделяю память под max_models штук при рисовке просто указываю смещение.
3. Storage Buffers
   Похожи на UBO, но могут быть гораздо большего размера и позволяют запись из шейдера (хотя у вас readonly). Идеально подходят для массивов данных переменного размера. В моем коде light_ssbo_buffer, я храню в нем массив PointLight и их количество. Это главное требование. 
4. Push Constants
   Самый быстрый способ передать крошечный объем данных (обычно не более 128-256 байт). Они передаются вместе с самой командой отрисовки, без использования отдельных буферов. В моем коде vkCmdPushConstants. Вы передаете в них все данные об окружающем, направленном и прожекторном свете, а также позицию камеры. Это очень грамотное решение, так как эти данные общие для всех объектов в кадре.

Кратко:
- Вершины -> Vertex Buffer
- Глобальные данные сцены (матрицы) -> UBO
- Массив чего-либо (источники света) -> SSBO
- Очень маленькие, часто меняющиеся данные -> Push Constants

### Командные буферы и дескрипторы

Командный буфер - приказ для GPU что-то делать. 
- render(VkCommandBuffer cmd, ...) - эта функция ничего не рисует, она записывает последовательность команд в cmd.
- vkBeginCommandBuffer, vkCmd..., vkEndCommandBuffer - процесс записи
- Только когда CPU отправляет этот командный буфер в очередь GPU (vkQueueSubmit, это делает veekay под капотом), армия рабочих начинает его выполнять.

А как шейдер узнает, откуда брать данные для UBO и SSBO? Через дескрипторы.
- VkDescriptorSet - таблица ссылок.
  В шейдере я: layout(set=0, binding=2) buffer LightSSBO, а на CPU говорю: "В set=0 на binding=2 положи, пожалуйста, ссылку на буфер light_ssbo_buffer"
- vkCmdBindDescriptorSets - говорим GPU: "Для следующих команд отрисовки используй вот это оглавление (descriptor_set)"

### Возможные вопросы и ответы к ним

В: Что такое рендер-пасс (VkRenderPass)?
О: Рендер-пасс описывает, с какими изображениями (attachments) мы работаем во время рендеринга. В вашем случае это два изображения: цветовой буфер (куда мы рисуем) и буфер глубины (для Z-теста, чтобы ближние объекты перекрывали дальние). Команда vkCmdBeginRenderPass говорит GPU "начать работу с этими изображениями, очистив их заданными цветами".

В: Объясните вашу реализацию камеры. В чем разница между двумя режимами?
О: У меня реализовано два режима.
    - Трансформационная модель: Камера рассматривается как объект в мире. У нее есть позиция (position) и углы Эйлера (rotation). Матрица вида (view) вычисляется как обратная трансформация камеры: сначала поворот в обратную сторону (-rotation), потом перенос в обратную сторону (-position). Это интуитивно понятно для управления "от первого лица".
    - Режим Look-At: Этот режим более математический. Мы задаем три вектора: позицию камеры (position), точку, куда смотреть (target), и вектор "верха" (обычно (0,1,0)). Функция look_at строит ортонормированный базис (систему координат) для камеры и вычисляет матрицу вида. Этот режим удобен для наблюдения за объектом со стороны. Переключение реализовано через флаг is_look_at.
  
В: Как работает модель освещения Блинн-Фонга? Чем она отличается от Фонга?
О: Модель Блинн-Фонга рассчитывает три компонента света:
    - Ambient (Рассеянный): Постоянный свет, который подсвечивает все поверхности одинаково, имитируя многократные отражения света в сцене.
    - Diffuse (Диффузный): Имитирует отражение света от матовых поверхностей. Его интенсивность зависит от угла между нормалью к поверхности и направлением на свет (dot(N, L)). Чем больше поверхность повернута к свету, тем она ярче.
    - Specular (Бликовый): Имитирует блики на глянцевых поверхностях. Ключевое отличие от Фонга: вместо вычисления отраженного от света вектора, мы вычисляем "вектор полупути" (H = normalize(L + V)), который лежит ровно посередине между направлением на свет (L) и направлением на камеру (V). Блик максимален, когда этот вектор H совпадает с нормалью N. Считается, что это дает более мягкие и физически правдоподобные блики и работает быстрее.
  
В: Как вы реализовали плавные края у прожектора?
О: Я использую два угла для конуса прожектора: внутренний (inner_cutOff) и внешний (outer_cutOff).
1. Я вычисляю косинус угла между вектором от пикселя к прожектору и направлением самого прожектора.
2. Если этот косинус меньше косинуса внешнего угла, пиксель находится вне света (интенсивность 0).
3. Если косинус больше косинуса внутреннего угла, пиксель полностью освещен (интенсивность 1).
4. Если косинус находится между этими двумя значениями, я плавно интерполирую интенсивность от 0 до 1. Это создает эффект мягкой полутени (penumbra) по краю светового пятна. В шейдер я передаю уже предрассчитанные косинусы углов, чтобы не вычислять cos() для каждого пикселя.

В (сложный вопрос): В вашем вершинном шейдере вы трансформируете нормаль как model * vec4(v_normal, 0.0f). В каком случае это приведет к неверному результату?
О: Этот способ работает корректно только для вращения и равномерного масштабирования. Если я применю неравномерное масштабирование (например, сплющу объект по одной из осей), нормали перестанут быть перпендикулярны поверхности. Правильный способ — использовать обратную транспонированную матрицу модели (transpose(inverse(model))) для трансформации нормалей.


### ПРОСТО

Копирование: Поскольку CPU не может напрямую писать в быструю DEVICE_LOCAL VRAM, происходит промежуточный шаг (который veekay прячет):
Создается временный "staging" буфер в памяти, видимой и CPU, и GPU (HOST_VISIBLE).
CPU копирует данные из vertices.data() в этот staging буфер.
В командный буфер записывается команда vkCmdCopyBuffer, которая приказывает GPU скопировать данные из staging буфера в финальный vertex_buffer.
Staging буфер уничтожается.