### GENETAL

Vulkan - язык приказов, который CPU использует, чтобы управлять GPU.
Vulkan — это очень строгий и детальный протокол, который описывает, как CPU должен подготовить данные, 
упаковать инструкции и отправить их на выполнение в GPU

### Rendering Pipeline

Это "сборочный конвейер" внутри GPU. Когда вы даете команду нарисовать треугольник, его данные (координаты вершин) проходят через несколько обязательных этапов:
    - Vertex input (Входные данные вершин)
    - Vertex Shader (Вершинный буфер)
    - Rasterization (Растеризация)
    - Fragment Shader (Фрагментный (пиксельный) шейдер)
    - Blending (Смешивание)

1. Vertex input
   GPU нужно получить сырые данные о моей модели из памяти. 
   В initialize я создаю plabe_mesh.vertex_buffer и cube_mesh.vertex_buffer. Это буферы в VRAM (память в GPU),
   куда я копирую данные из векторов vertices. Структура Vertex описывает, что лежит в этом буфере для каждой
   вершины.
2. Vertex Shader
   Маленькая программа, которая выполняется GPU для каждой вершины индивидуально. Задача - взять позицию
   вершины в локальных координатах модели и вычислить ее финальную позицию на экране.
   У меня это происходит в shader.verts
3. Rasterization
   GPU берет 3 обработанные вершины, которые образуют треугольник, и определяет, какие пиксели на экране попадают внутрь. На этом этапе он также интерполирует (плавно изменяет) данные, которые мы получили от вершинного шейдера (например, нормаль f_normal) для каждого пикселя. а этом этапе он также интерполирует (плавно изменяет) данные, которые мы получили от вершинного шейдера (например, нормаль f_normal) для каждого пикселя. Если у одной вершины нормаль смотрит вверх, а у другой вбок, то у пикселя посередине нормаль будет смотреть по диагонали.
   У меня настраивается в initialize через VkPipelineRasterizationStateCreateInfo.
4. Fragment Shader
   Вторая маленькая программа. Выполняется для каждого пикселя, который попал внутрь треугольника на этапе растеризации. Задача - определить, каким цветом будет пиксель. Здесь же происходит "магия" освещения.
   У меня это shader.frag.
5. Blending
   Последний этап. Если пиксель уже чем-то закрашен (например, за треугольником есть другой), GPU решает, что с этим делать. Смешать цвета (для прозрачности) или просто переписать старый цвет новым.
   У меня в коде настраивается в VkPipelineColorBlendStateCreateInfo.


### Передача данных в GPU

1. Vertex Buffers
   Это большие объемы данных, описывающие геометрию. Позиции, нормали, UV-координаты.
   В моем коде plane_mesh.vertex_buffer. Обычно загружаются в VRAM 1 раз и больше не меняются.
2. Uniform Buffers
   Небольшие объемы данных, которые являются общими для целого вызова отрисовки (матрица проекции или позиция камеры). В моем коде: scene_uniforms_buffer (хранит view_projection) - обновляется один раз за кадр; model_uniforms_buffer (хранит model, albedo_color) - Dynamic UBO. Выделяю память под max_models штук при рисовке просто указываю смещение.
3. Storage Buffers
   Похожи на UBO, но могут быть гораздо большего размера и позволяют запись из шейдера (хотя у вас readonly). Идеально подходят для массивов данных переменного размера. В моем коде light_ssbo_buffer, я храню в нем массив PointLight и их количество. Это главное требование. 
4. Push Constants
   Самый быстрый способ передать крошечный объем данных (обычно не более 128-256 байт). Они передаются вместе с самой командой отрисовки, без использования отдельных буферов. В моем коде vkCmdPushConstants. Вы передаете в них все данные об окружающем, направленном и прожекторном свете, а также позицию камеры. Это очень грамотное решение, так как эти данные общие для всех объектов в кадре.

Кратко:
- Вершины -> Vertex Buffer
- Глобальные данные сцены (матрицы) -> UBO
- Массив чего-либо (источники света) -> SSBO
- Очень маленькие, часто меняющиеся данные -> Push Constants

### Командные буферы и дескрипторы

Командный буфер - приказ для GPU что-то делать. 
- render(VkCommandBuffer cmd, ...) - эта функция ничего не рисует, она записывает последовательность команд в cmd.
- vkBeginCommandBuffer, vkCmd..., vkEndCommandBuffer - процесс записи
- Только когда CPU отправляет этот командный буфер в очередь GPU (vkQueueSubmit, это делает veekay под капотом), армия рабочих начинает его выполнять.

А как шейдер узнает, откуда брать данные для UBO и SSBO? Через дескрипторы.
- VkDescriptorSet - таблица ссылок.
  В шейдере я: layout(set=0, binding=2) buffer LightSSBO, а на CPU говорю: "В set=0 на binding=2 положи, пожалуйста, ссылку на буфер light_ssbo_buffer"
- vkCmdBindDescriptorSets - говорим GPU: "Для следующих команд отрисовки используй вот это оглавление (descriptor_set)"

### Возможные вопросы и ответы к ним

В: Что такое рендер-пасс (VkRenderPass)?
О: Рендер-пасс описывает, с какими изображениями (attachments) мы работаем во время рендеринга. В вашем случае это два изображения: цветовой буфер (куда мы рисуем) и буфер глубины (для Z-теста, чтобы ближние объекты перекрывали дальние). Команда vkCmdBeginRenderPass говорит GPU "начать работу с этими изображениями, очистив их заданными цветами".

В: Объясните вашу реализацию камеры. В чем разница между двумя режимами?
О: У меня реализовано два режима.
    - Трансформационная модель: Камера рассматривается как объект в мире. У нее есть позиция (position) и углы Эйлера (rotation). Матрица вида (view) вычисляется как обратная трансформация камеры: сначала поворот в обратную сторону (-rotation), потом перенос в обратную сторону (-position). Это интуитивно понятно для управления "от первого лица".
    - Режим Look-At: Этот режим более математический. Мы задаем три вектора: позицию камеры (position), точку, куда смотреть (target), и вектор "верха" (обычно (0,1,0)). Функция look_at строит ортонормированный базис (систему координат) для камеры и вычисляет матрицу вида. Этот режим удобен для наблюдения за объектом со стороны. Переключение реализовано через флаг is_look_at.
  
В: Как работает модель освещения Блинн-Фонга? Чем она отличается от Фонга?
О: Модель Блинн-Фонга рассчитывает три компонента света:
    - Ambient (Рассеянный): Постоянный свет, который подсвечивает все поверхности одинаково, имитируя многократные отражения света в сцене.
    - Diffuse (Диффузный): Имитирует отражение света от матовых поверхностей. Его интенсивность зависит от угла между нормалью к поверхности и направлением на свет (dot(N, L)). Чем больше поверхность повернута к свету, тем она ярче.
    - Specular (Бликовый): Имитирует блики на глянцевых поверхностях. Ключевое отличие от Фонга: вместо вычисления отраженного от света вектора, мы вычисляем "вектор полупути" (H = normalize(L + V)), который лежит ровно посередине между направлением на свет (L) и направлением на камеру (V). Блик максимален, когда этот вектор H совпадает с нормалью N. Считается, что это дает более мягкие и физически правдоподобные блики и работает быстрее.
  
В: Как вы реализовали плавные края у прожектора?
О: Я использую два угла для конуса прожектора: внутренний (inner_cutOff) и внешний (outer_cutOff).
1. Я вычисляю косинус угла между вектором от пикселя к прожектору и направлением самого прожектора.
2. Если этот косинус меньше косинуса внешнего угла, пиксель находится вне света (интенсивность 0).
3. Если косинус больше косинуса внутреннего угла, пиксель полностью освещен (интенсивность 1).
4. Если косинус находится между этими двумя значениями, я плавно интерполирую интенсивность от 0 до 1. Это создает эффект мягкой полутени (penumbra) по краю светового пятна. В шейдер я передаю уже предрассчитанные косинусы углов, чтобы не вычислять cos() для каждого пикселя.

В (сложный вопрос): В вашем вершинном шейдере вы трансформируете нормаль как model * vec4(v_normal, 0.0f). В каком случае это приведет к неверному результату?
О: Этот способ работает корректно только для вращения и равномерного масштабирования. Если я применю неравномерное масштабирование (например, сплющу объект по одной из осей), нормали перестанут быть перпендикулярны поверхности. Правильный способ — использовать обратную транспонированную матрицу модели (transpose(inverse(model))) для трансформации нормалей.


### ПРОСТО

Копирование: Поскольку CPU не может напрямую писать в быструю DEVICE_LOCAL VRAM, происходит промежуточный шаг (который veekay прячет):
Создается временный "staging" буфер в памяти, видимой и CPU, и GPU (HOST_VISIBLE).
CPU копирует данные из vertices.data() в этот staging буфер.
В командный буфер записывается команда vkCmdCopyBuffer, которая приказывает GPU скопировать данные из staging буфера в финальный vertex_buffer.
Staging буфер уничтожается.

ИТОГ ПУТИ:
CPU:
1. Создаем Model с material.albedo = red.
2. В update() копируем red в ModelUniforms.
3. Копируем ModelUniforms в model_uniforms_buffer со смещением offset.
4. В render() отдаем команду vkCmdBindDescriptorSets с тем же offset.
5. Отдаем команду vkCmdDrawIndexed.
GPU (Шейдеры):
6. shader.frag запускается для пикселя.
7. Он читает uniform ModelUniforms. GPU, зная offset, находит в памяти и считывает red.
8. red используется в формуле освещения.
9. Итоговый цвет записывается на экран.





// описываем геометрию объекта	
struct Mesh {
	veekay::graphics::Buffer* vertex_buffer; // Указатель на буфер в VRAM, где лежат координаты, нормали и UV всех вершин (углов) объекта.
	veekay::graphics::Buffer* index_buffer; // Указатель на буфер, который говорит, в каком порядке соединять вершины, чтобы получить треугольники.
	uint32_t indices; // Количество индексов. Нужно для команды отрисовки.
};

Пример: cube_mesh и plane_mesh — это два разных экземпляра этой структуры, описывающие геометрию куба и плоскости.

// Внешний вид поверхности объекта
struct Material {
	veekay::vec3 albedo = {1.0f, 1.0f, 1.0f}; // основной цвет объекта
	float _pad0;
	veekay::vec3 specular = {1.0f, 1.0f, 1.0f}; // цвет блика
	float shininess = 32.0f; // чем больше, тем меньше и ярче блик
};

// Как данные об одном объекте лежат в GPU
struct ModelUniforms {
	veekay::mat4 model; ..Матрица модели. Отвечает за положение, поворот и размер этого конкретного объекта в сцене.
   // поля, куда копируем данные из Material
	veekay::vec3 albedo_color;
	float shininess;
	veekay::vec3 specular_color;
	float _pad;
};
Ключевое отличие от Material: ModelUniforms — это "транспортная" структура для передачи данных в GPU, она должна быть совместима с правилами выравнивания памяти в шейдерах (поэтому там есть _pad). Material — это просто удобная C++ структура для хранения этих данных на стороне CPU.

// описываем один полноценный объект
struct Model {
	Mesh mesh; // "Какую геометрию использовать?" (например, cube_mesh).
	Transform transform; // "Где в мире этот объект находится, как он повернут и какого он размера?". Из transform вычисляется матрица model для ModelUniforms.
	Material material; // "Как выглядит поверхность этого объекта?" (его цвет, блеск и т.д.).
};

veekay::mat4 view() const; // вычисляем и возвращаем матрицу вида
Матрица вида преобразует координаты из мирового пространства в пространство камеры. Проще говоря, она "устанавливает камеру" в определенной точке и поворачивает ее в нужном направлении. Она делает так, чтобы мир "двигался" обратно движению камеры.
Как работает:
   Внутри она проверяет флаг is_look_at и либо вычисляет матрицу на основе position и rotation (твой вариант 1), либо на основе position, target и up (доп. задание).

veekay::mat4 view_projection(float aspect_ratio) const; // матрица вида * матрицу проекции
Матрица проекции "сплющивает" 3D-мир в 2D-изображение, создавая эффект перспективы (дальние объекты меньше). Объединение View и Projection в одну матрицу — это стандартная оптимизация. Результат этой функции мы записываем в SceneUniforms и отправляем в шейдер.


struct LightSSBO {
	PointLight point_lights[max_point_lights];
	uint32_t point_light_count = 0;
	veekay::vec3 _pad[3];
};
Что это: C++ структура, которая точно повторяет структуру данных в шейдере для SSBO (Shader Storage Buffer Object). Это наш "контейнер" для всех точечных источников света, который мы целиком скопируем в память GPU.


// обертка вокруг SPIR-V кода. Просто ресурс, который подключаю к конвейеру
	VkShaderModule vertex_shader_module;
Что это: "Ручка" к скомпилированному коду шейдера (SPIR-V), загруженному в память.
Аналогия: Это как exe-файл для твоей программы. Он сам по себе не работает, пока ты его не запустишь. vertex_shader_module — это exe для вершинного шейдера, fragment_shader_module — для фрагментного.

// описание интерфейса между шейдерами и данными, передаваемыми из кода
	VkPipelineLayout pipeline_layout;
Что он описывает: Он описывает ДВЕ вещи:
   - Какие Descriptor Sets будут использоваться. Он хранит в себе указатель на descriptor_set_layout. Это говорит конвейеру: "Будь готов принять один Descriptor Set, который соответствует вот этому шаблону (с binding 0 для UBO, 1 для Dynamic UBO, 2 для SSBO)".
   - Какие Push Constants будут использоваться. Он описывает, сколько байт push-констант вы будете передавать и в каких шейдерах они будут доступны (stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT).
Зачем он нужен: Чтобы Vulkan мог заранее проверить, что данные, которые вы пытаетесь привязать (vkCmdBindDescriptorSets) или передать (vkCmdPushConstants), соответствуют тому, чего ожидают шейдеры. Это строгий контракт. VkPipeline (следующий пункт) не может быть создан без VkPipelineLayout.


// сконфигурированный графический конвейер
	VkPipeline pipeline;
Что он "запекает" в себе: Всё. Вообще всё, что касается состояния GPU во время отрисовки:
   - Шейдеры: Какие VkShaderModule использовать для вершинной и фрагментной стадий.
   - Формат входных данных: Как интерпретировать данные из вершинного буфера (структура Vertex).
   - Способ сборки: Что вершины образуют треугольники (VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST).
   - Состояние растеризатора: Заливать треугольники сплошным цветом, отбрасывать задние грани.
   - Состояние теста глубины: Включен ли Z-тест, как он сравнивает глубину.
   - Состояние смешивания цветов: Как цвет из фрагментного шейдера смешивается с тем, что уже есть в пикселе.
   - Интерфейс: Ссылка на pipeline_layout, который мы разобрали выше.
Это цель всей функции initialize. Вы создаете этот гигантский объект состояния один раз при запуске, чтобы потом в цикле рендеринга просто сказать GPU: "Используй вот этот конвейер" (vkCmdBindPipeline). Это невероятно эффективно, потому что драйверу не нужно каждый кадр заново решать, как ему рисовать треугольники. Он просто активирует уже готовую, скомпилированную "программу" для GPU.


VkShaderModule result;
	// veekay::app.vk_device - логическое устройство GPU
	// &info - указатель на VkShaderModuleCreateInfo (где инфа о шейдере)
	// nullptr - указатель на аллокатор памяти (используем базовый)
	if (vkCreateShaderModule(veekay::app.vk_device, &info, nullptr, &result) != VK_SUCCESS) {
		return nullptr;
	}
Что делает функция:
   - Она берет информацию из info.
   - Проверяет байт-код шейдера на корректность (является ли он валидным SPIR-V).
   - Создает внутри драйвера, в памяти GPU, внутренний объект, представляющий этот скомпилированный шейдер.
   - Записывает в нашу переменную result (по переданному адресу &result) уникальный идентификатор (дескриптор) этого созданного объекта.

мультисемплинг - Это техника сглаживания "лесенек" на краях объектов. Вместо того, чтобы считать цвет для одного центрального сэмпла (точки) внутри пикселя, GPU считает его для нескольких сэмплов (2x, 4x, 8x), а потом усредняет результат. Это делает края объектов более гладкими.


Descriptor Set — это просто массив адресов памяти GPU. Он нужен, чтобы отделить "что рисовать" (vkCmdDraw) от "с какими данными" (vkCmdBindDescriptorSets). Это позволяет GPU быть очень эффективным: он может получить один приказ "используй вот этот набор данных" и потом выполнить 1000 команд vkCmdDraw с этим набором, не тратя время на поиск адресов для каждого объекта.




VkPipelineLayout — это полный "контракт" или "API" ваших шейдеров.
Он формально описывает все внешние данные, которые шейдеры могут запросить.
Этот объект нужен в двух местах:
   - При создании VkPipeline: Графический конвейер "запекает" в себе этот layout. Это позволяет драйверу скомпилировать и оптимизировать шейдеры, точно зная, откуда они будут брать данные.
   - При записи команд в VkCommandBuffer:
      - Когда ты вызываешь vkCmdBindDescriptorSets(..., pipeline_layout, ...)
      - Когда ты вызываешь vkCmdPushConstants(..., pipeline_layout, ...)
      - Ты передаешь pipeline_layout в эти функции. Vulkan использует его для проверки: "Действительно ли в layout'е для set=0 есть binding=2? Действительно ли layout разрешает передавать 128 байт push-констант во фрагментный шейдер?". Это обеспечивает строгий контроль и предотвращает ошибки.




Графический конвейер — это последовательность программируемых и фиксированных этапов на GPU, которая преобразует набор математических описаний (вершины, треугольники) в двумерное изображение (массив пикселей).
Конвейер выглядит так:
   - Входные данные (Input Assembler): GPU читает твои cube_mesh.vertex_buffer и cube_mesh.index_buffer, чтобы собрать данные для треугольников.
   - Вершинный шейдер (Vertex Shader): Запускается твой shader.vert. Он получает v_position и v_normal, вычисляет gl_Position и передает f_position и f_normal дальше.
   - Растеризация (Rasterization): Непрограммируемый этап. GPU:
       - Берет три gl_Position и определяет, какие пиксели экрана покрыты треугольником.
       - Для каждого такого пикселя выполняет барицентрическую интерполяцию для f_position и f_normal.
   - Фрагментный шейдер (Fragment Shader): Запускается твой shader.frag для каждого пикселя. Он получает интерполированные f_position и f_normal. Используя их, а также данные из uniform-буферов (model, pc) и SSBO (lights), он вычисляет final_color.
   - Выходной этап (Output Merger): GPU берет final_color, выполняет тест глубины и записывает итоговый цвет в framebuffer, который ты видишь на экране.




Текстурирование в графическом конвейере.
1. На вход подается зеленый треугольник. Это твои "сырые" данные — координаты вершин из vertex_buffer.
2. Vertex Shader (Вершинный шейдер):
   1. Что делает: Принимает вершины треугольника и изменяет их положение. На картинке видно, что вершины выходного треугольника сместились.
   2. Как это связано с твоим кодом: Это в точности твой файл shader.vert. Его главная задача — взять входную позицию v_position и вычислить финальную позицию gl_Position.
3. Rasterizer (Растеризатор):
   1. Что делает: Берет три обработанные вершины и определяет, какие пиксели на экране попадают внутрь этого треугольника. Он превращает векторную фигуру (треугольник) в набор пикселей (фрагментов). На картинке это показано как заштрихованная сетка пикселей. Как это связано с твоим кодом: Это аппаратный этап GPU. Ты не пишешь для него код, но ты его настраиваешь в main.cpp через структуру VkPipelineRasterizationStateCreateInfo (где ты указываешь polygonMode = VK_POLYGON_MODE_FILL).
4. Fragment Shader (Фрагментный шейдер):
   1. Что делает: Выполняется для каждого пикселя, найденного растеризатором. Его задача — определить финальный цвет этого пикселя. На картинке показано, что он берет данные от растеризатора, берет текстуру кирпича и на выходе выдает окрашенный пиксель (в итоге получается чайник с текстурой кирпича).
   2. Как это связано с твоим кодом: Это в точности твой файл shader.frag. Его работа — вычислить final_color для каждого пикселя, используя данные о нормалях, материалах и источниках света.



Про растеризацию
Цель растеризации: Взять три вершины, образующие треугольник в пространстве экрана, и сгенерировать для фрагментного шейдера список всех пикселей, которые этот треугольник покрывает.

Шаг 1: Настройка треугольника (Triangle Setup)
Вход: Растеризатор получает три обработанные вершины из твоего shader.vert. Для каждой вершины он знает:
Ее финальные экранные координаты (из gl_Position).
Значения всех out переменных (f_position, f_normal, f_uv).
Действие: GPU вычисляет "дельта-значения" и уравнения ребер треугольника. По сути, он математически описывает три линии, образующие стороны треугольника. Это подготовка для следующего шага.

Шаг 2: Сканирование (Scan Conversion)
Задача: Найти все пиксели, которые могут принадлежать треугольнику.
Действие:
- GPU определяет ограничивающий прямоугольник (bounding box) вокруг треугольника. Это самый маленький прямоугольник, в который полностью вписывается треугольник.
- GPU не будет проверять все пиксели экрана. Он будет итерировать только по тем пикселям, центры которых находятся внутри этого прямоугольника. Это огромная оптимизация.

Шаг 3: Тест "Внутри/Снаружи" (Inside/Outside Test)
Задача: Для каждого пикселя из bounding box'а определить, находится ли он действительно внутри треугольника.
Действие:
Для центра каждого пикселя GPU выполняет тест покрытия. Самый распространенный метод — "edge functions".
- Представь, что каждая сторона треугольника — это бесконечная линия, которая делит экран на две полуплоскости.
Для каждой из трех сторон GPU определяет, находится ли центр пикселя "справа" или "слева" от этой линии (математически это делается с помощью знака результата векторного произведения).
- Если центр пикселя находится с "правильной" стороны от всех трех линий одновременно, то он считается покрытым треугольником. Если хотя бы для одной линии он с "неправильной" стороны — пиксель отбрасывается.

Шаг 4: Интерполяция атрибутов (Attribute Interpolation)
Это самый важный шаг, который объясняет картинку с формулой.
Задача: Для каждого пикселя, который прошел тест "внутри", вычислить значения атрибутов (f_position, f_normal, f_uv), которые будут переданы во фрагментный шейдер.
Действие:
- Для этого пикселя GPU вычисляет его барицентрические координаты (α, β, γ).
   - Это три "веса", которые показывают, насколько пиксель близок к каждой из трех вершин треугольника (v₀, v₁, v₂).
   - Если пиксель находится точно на вершине v₀, его координаты будут {α=1, β=0, γ=0}.
   - Если пиксель находится ровно посередине ребра между v₀ и v₁, его координаты {α=0.5, β=0.5, γ=0}.
   - Сумма α + β + γ всегда равна 1.
- GPU использует эти веса для линейной интерполяции всех out переменных из вершинного шейдера, используя ту самую формулу с твоей картинки: u = α u₀ + β u₁ + γ u₂.

Применительно к твоему коду:
   - interpolated_f_normal = α * f_normal_at_v0 + β * f_normal_at_v1 + γ * f_normal_at_v2;
   - interpolated_f_uv = α * f_uv_at_v0 + β * f_uv_at_v1 + γ * f_uv_at_v2;
Результат:
Для каждого покрытого пикселя генерируется фрагмент. Фрагмент — это, по сути, "кандидат в пиксели", который содержит:
   - Координаты пикселя на экране.
     - Интерполированные значения всех атрибутов (f_position, f_normal и т.д.).